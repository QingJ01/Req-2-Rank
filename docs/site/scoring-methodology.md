# 评分方法

本页详述 Req2Rank 如何将多个评审模型的打分聚合为一个可信的综合分数。

## 评分流程总览

```
收集各评审员的原始分数
       ↓
计算每个维度的 IJA（评审一致性）
       ↓
判断是否满足去极值条件
       ↓
计算各维度加权均值
       ↓
计算综合总分
       ↓
计算 95% 置信区间
       ↓
生成 warnings（如有分歧过大的维度）
```

---

## 评分维度

每个评审模型独立为代码产出打分，打分维度和权重如下：

| 维度 | 键名 | 权重 | 评估内容 |
|------|------|------|---------|
| **功能完整性** | `functionalCompleteness` | 30% | 是否实现了需求中的所有功能点 |
| **代码质量** | `codeQuality` | 25% | 命名规范、模块化、可读性、代码风格 |
| **逻辑准确性** | `logicAccuracy` | 25% | 算法正确性、边界条件处理、逻辑严密性 |
| **安全性** | `security` | 10% | 是否存在注入漏洞、硬编码密钥、不安全的操作 |
| **工程实践** | `engineeringPractice` | 10% | 错误处理、日志记录、文档注释、测试覆盖 |

每个维度满分 100 分。

### 总分公式

```
overallScore = Σ(dimensionScore_i × weight_i)
```

例如：功能完整性 86 × 0.3 + 代码质量 82 × 0.25 + 逻辑准确性 85 × 0.25 + 安全性 80 × 0.1 + 工程实践 83 × 0.1 = **83.85**

---

## IJA — 评审一致性分析

IJA（Inter-Judge Agreement）衡量多个评审模型之间的打分共识程度。

### 计算方法

对每个维度，收集所有评审员的分数，计算**标准差 σ**：

| σ 范围 | 一致性等级 | 含义 |
|--------|----------|------|
| σ ≤ 8 | `high` | 评审员基本一致，结果可靠 |
| 8 < σ ≤ 15 | `moderate` | 存在一定分歧但可接受 |
| σ > 15 | `low` | 严重分歧，结果需谨慎对待 |

总体一致性 = 各维度 σ 的均值，再按上述阈值判定。

### 分歧处理

当某维度的一致性为 `low` 时：
- 报告中会生成 ⚠️ warning（例如 `security dimension has low agreement (σ=18.5)`）
- **不做去极值处理**（分歧大时去极值反而丢失信息）
- 提交到排行榜时附带置信区间，UI 显示误差线

---

## 去极值策略

为降低极端评分的影响，满足以下条件时启用去极值（Trimmed Mean）：

| 条件 | 要求 |
|------|------|
| 评审员数量 | ≥ 3 |
| 总体一致性 | 不为 `low` |

**去极值方式**：对每个维度，将评审分数排序后移除最高分和最低分，再对剩余分数求均值。

如果不满足条件，直接对全部原始分数求均值。

---

## CI95 — 95% 置信区间

置信区间（Confidence Interval）表示综合得分的统计可靠范围。

### 计算方法

1. 对每个评审员，先计算其加权总分（按维度权重加权）
2. 对所有评审员的总分计算样本标准差 `stdDev`
3. 计算边际误差：

```
margin = 1.96 × (stdDev / √n)
```

4. 置信区间：

```
CI95 = [overallScore - margin, overallScore + margin]
```

其中 `n` 为参与计算的评审样本数（若启用去极值则为去极值后的样本）。

### 示例

3 个评审员的总分分别为 82, 85, 81：
- 均值 = 82.67
- stdDev ≈ 2.08
- margin = 1.96 × (2.08 / √3) ≈ 2.35
- **CI95 = [80.3, 85.0]**

---

## 排行榜上的分数

Hub 排行榜支持三种聚合策略，用户可在页面切换：

| 策略 | 说明 |
|------|------|
| `mean` | 该模型所有提交的平均分 |
| `best` | 该模型历史最高分 |
| `latest` | 该模型最近一次提交的分数 |

每个分数都附带 CI95 置信区间和验证状态（`verified` / `pending` / `disputed`）。

---

## 在哪里查看结果

| 场景 | 命令 / 入口 |
|------|------------|
| 终端报告 | `req2rank report <run-id>` |
| 导出文件 | `req2rank export --latest --format markdown` |
| 排行榜 | [req2rank.top](https://req2rank.top) |
